<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<!-- saved from url=(0073)https://cservan.github.io/tp3_POS_tagging.html -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	
	<title>Demo 2: Part-of-Speech Tagging part 3: Deep Learning for NLU</title>
<link href="chrome-extension://lnkdbjbjpnpjeciipoaflmpcddinpjjp/mytube.css" rel="stylesheet" type="text/css"><script src="chrome-extension://lnkdbjbjpnpjeciipoaflmpcddinpjjp/mutationObserver.js"></script><script src="chrome-extension://lnkdbjbjpnpjeciipoaflmpcddinpjjp/mytube.js"></script></head>
<body lang="fr-FR" text="#000000" dir="ltr" style="background: transparent">
	<h1 align="center">Demo 2: Part-of-Speech Tagging <br> Deep Learning for NLU</h1>
<h3 align="center">Christophe Servan 
</h3>
<h2>Introduction</h2>
<p>
In this demo you will learn how to process PoS tagging using Machine Translation approach.
</p>
<p>
This is a very common way to proceed, since Statistical Machine Translation approaches where widely used. 
</p>

	<hr>


<h2>Toolkits</h2>

<ul>
  <li>OpenNMT: use pip to install OpenNMT like this <pre> sudo -EH python3 -m pip install OpenNMT-tf </pre></li>
</ul>

<hr>
<h2>Data</h2>
	<ul>
		<li>Train and test set are available <a href="https://cservan.github.io/data/tp3_files.tgz">here</a> and additionnal configuration files for OpenNMT <a href="https://cservan.github.io/tools/seq_tagger_data.tar.gz">here</a>.
		</li><li>Decompress then using tar:<pre>tar xvfz tp3_files.tgz </pre> <b>or</b> <pre>gunzip tp3_files.tgz </pre> and then <pre>tar xvf tp3_files.tar </pre>
	</li></ul>

<hr>
<!--	<h2>Report
	</h2>
	<p>You should send me your report <u><b>the day before the next session</b></u> using <b>PDF</b> format
	at the address christophe_dot_servan_at_epita_dot_fr (replace
	_dot_ and _at_ by dots and at, respectively) </p><p>
	<em>Remarks:</em>
	</p><ul>
                <li>If you encounter some issues, feel free to send me an email, I'll answer you ASAP;
                </li><li><b>NO jupyternotes</b> nor scripts: they will be ignored. I want you to write a report. This also means you have to put your name on it and to do an effort of presentation! ;-)
                </li><li>The report mark is important for the final course mark ;
                </li><li>You have to report working in groups, if you did so (ask me before) ;
                </li><li>If you send me your report lately, you will be penalised ;
                </li><li>Plagianism equal to zero ;
                </li><li>No report equal to zero ;
	</li></ul>
	<p></p>
	<hr> -->
	<h2>Work to do</h2>
	<ol>
		<ol>
			This demo you will work with a NMT toolkit to perform PoS tagging: 
			<ul>
				<li>Fristly you will find how to set the dataset to the right format (bitext). 
				</li><li>Then you will find how to train your model. 
				</li><li>Finally, you will test your model and give feed backs. 
			</li></ul>
	</ol>
	<h3>I. Creating data</h3>
	<ol>
		<p>The main idea is to fits the raw data to the format. you will find additionnal informations in the documentation <a href="https://opennmt.net/OpenNMT-tf/">here</a></p>
		
		<p><b>WARNING:</b> Read carefully the documentation. if the file is not at the right format it won't work.</p>
		<p>Bitexts are sentence align text generally separated in two files. In our case, the amount of words per line have to be the same. Here is an example: </p>
		<pre>
==> train.src (source) <==
Confidence in the pound is widely expected to take another sharp dive if trade figures for September , due for release tomorrow , fail to show a substantial improvement from July and August 's near-record deficits . 
Chancellor of the Exchequer Nigel Lawson 's restated commitment to a firm monetary policy has helped to prevent a freefall in sterling over the past week . 
But analysts reckon underlying support for sterling has been eroded by the chancellor 's failure to announce any new policy measures in his Mansion House speech last Thursday . 
		
==> train.tgt (target)<==
NN IN DT NN VBZ RB VBN TO VB DT JJ NN IN NN NNS IN NNP PUNCT JJ IN NN NN PUNCT VB TO VB DT JJ NN IN NNP CC NNP POS JJ NNS PUNCT 
NNP IN DT NNP NNP NNP POS VBN NN TO DT NN JJ NN VBZ VBN TO VB DT NN IN NN IN DT JJ NN PUNCT 
CC NNS VBP VBG NN IN NN VBZ VBN VBN IN DT NN POS NN TO VB DT JJ NN NNS IN PRP$ NNP NNP NN JJ NNP PUNCT 
		</pre>
		<ol>
			<p><strong>Exercice 1:</strong> You have to create bitext for train, valid and test set composed of words (source) and labels (target).
			</p><ol>
				<p><strong>Q1:</strong> Give the bash command to transform original data into bitexts, the valid set should be an extract of 1000 lines from the train set. (1pt)</p>
				<p><strong>Q2:</strong> Then, extract three vocabularies from train set using <tt>onmt-build-vocab</tt> use the <tt>char_tokenization.yml</tt> file for the character tokenization(2pt) :<ul>
                                            <li> words from the source part of the train set </li>
                                            <li> character from the source part of the train set</li>
                                            <li> tags from the target part of the train set</li>
                                            </ul>
                                            </p>
				<p><strong>Q3:</strong> Give details about the amount of train and test data available for your experiments. (1pt)</p>
				 </ol>
			<p></p>
        </ol>
	</ol>
	<h3>II. Training the DL model</h3>
	<ol>
		<p>
        The main idea is to train your model using the data you processed.
		</p> 
		 
		<ol>
			<p><strong>Exercice 1:</strong> Set up the training by set up the config file (given in the additionnal data for OpenNMT) and then launch the training</p>
			<ol>
				<p><strong>Q1: </strong> What is your command line needed to launch the training? (1pt)</p>
                <p></p>
				<p><strong>Q2: </strong> How long was your training? (1pt)</p>		 
			</ol>
		</ol>
	</ol>
	<h3>III. Evaluation</h3>
	<ol>
		<p> Now you have your DL model, you will evaluate it using </p>
		<p><em>Remark: </em> You will use script <tt>eval.py</tt> to evaluate your results.</p>
		<ol>
			<p><strong>Exercice 1:</strong> Evaluation of the test set</p>
			<ol>
				<p><strong>Q1: </strong> Give the necessary commands to launch the evaluation of the model on the test set. (3pts)</p>
				<p><strong>Q2: </strong> Give evaluation scores given by the script <tt>eval.py</tt> and explain them. (5pts)</p>
			</ol>
			<!-- <p><strong>Exercice 2:</strong> Data Analysis </p> -->
			<!-- <ol> -->
				<!-- <p><strong>Q1: </strong> Compare your results with the FST &amp; CRF outputs, what are the improvements? Feel free to give statistics about it. (2pts)</p> -->
				<!-- <p><strong>Q2: </strong> Give example of improvement observed why are they representatives. (2pts)</p> -->
                <!-- <p></p> -->
			<!-- </ol> -->
		</ol>
	</ol>
</ol>
 <br> <br>The End.

</body></html>
